
#### Knowledge based agent

TODO add knowledge based agent def

**Simple knowledge based agent**

```
function KB-AGENT(percept) returns an action  
	static: KB, a knowledge base  
		t, a counter, initially 0, indicating time  
	TELL (KB, MAKE-PERCEPT-SENTENCE(percept, t))  
	action â† ASK (KB, MAKE-ACTION -QUERY(t))  
	TELL (KB, MAKE-ACTION -SENTENCE(action, t))  
	t â† t + 1  
	return action
```

TELL function hides details of the inference mechanism. MAKE-ACTION/MAKE-PERCEPT functions hide details of the representation language.

**Example: Wumpus world**

Wumpus World PEAS description:

* Performance measure:  
		gold +1000, death -1000, -1 per step, -10 for using the arrow  
* Environment:  
		4x4 grid of rooms, start in \[1,1], random location of gold and wumpus  
		0.2 probability of pit in a square (except in start position)  
* Actuators: Left turn 90,  Right turn 90, Forward, Shoot, Grab, Climb  
		Moving in square with live wumpus or pit results in death  
		Moving towards a wall has no effect  
		Shooting kills wumpus if you are facing it  
		Shooting uses up the only arrow  
		Grabbing picks up gold if in same square  
		Climbing exits the cave (only from \[1,1])  
* Sensors: Stench, Breeze, Glitter, Bump, Scream  
		Stench in squares orthogonally adjacent to wumpus  
		Breeze in squares orthogonally adjacent to pit  
		Glitter if gold is in the same square  
		Bump when walking into a wall  
		Scream in whole cave when wumpus gets killed
		
![[Screenshot 2023-11-14 at 11.15.14â€¯AM.png|200]]

Wumpus world characterization:

* Fully observable??
	* No - only local perception  
* Deterministic?? 
	* Yes - outcomes exactly specified  
* Episodic?? 
	* No â€“ a decision could affect future decisions  
* Static?? 
	* Yes - Wumpus and Pits do not move  
* Discrete?? 
	* Yes â€“ space, time, percepts and actions  
* Single-agent?? 
	* Yes - Wumpus is essentially a natural feature


Exploring the world

![[Screenshot 2023-11-14 at 11.17.46â€¯AM.png|300]]|![[Screenshot 2023-11-14 at 11.20.38â€¯AM.png|300]]

#### Logic in general

How do we represent the knowledge and perform reasoning with logic?

**Logics** are formal languages for representing information such that conclusions can be drawn  
**Syntax** defines the sentences in the language  
**Semantics** define the â€œmeaningâ€ of sentences;  
	i.e., define truth of a sentence in a world  
E.g., the language of arithmetic  
* Syntax:  
	$ğ‘¥ + 2 \geq ğ‘¦$ is a sentence; $ğ‘¥2 + ğ‘¦ >$ is not a sentence  
* Semantics:  
	$ğ‘¥ + 2 â‰¥ ğ‘¦$ is true iif the number $ğ‘¥ + 2$ is no less than the number $ğ‘¦$  
	$ğ‘¥ + 2 â‰¥ ğ‘¦$ is true in a world where $ğ‘¥ = 7, ğ‘¦ = 1$  
	$ğ‘¥ + 2 â‰¥ ğ‘¦$ is false in a world where $ğ‘¥ = 0; ğ‘¦ = 6$ 

#### Entailment

Entailment means that a sentence follows logically from another:  
$$ğ¾ğµ |= \alpha$$
Knowledge base ğ¾ğµ entails sentence $\alpha$ **if and only if**  $\alpha$ is true in all possible worlds where ğ¾ğµ is true  

E.g., the KB containing â€œthe Giants wonâ€ and â€œthe Reds wonâ€ entails â€œEither the Giants won or the Reds wonâ€  
E.g., ğ‘¥ = 0 entails ğ‘¥ğ‘¦ = 0  

Entailment is a relationship between sentences (i.e., syntax) that is based on semantics.

#### Models

>â€œpossible worldsâ€ = models

Logicians typically think in terms of models, which are formally structured worlds with respect to which truth can be evaluated.
We say ğ‘š is a model of a sentence $\alpha$ if $\alpha$ is true in ğ‘š.

$M(\alpha)$ is the set of all models of $\alpha$
Then $ğ¾ğµ |= \alpha$ **if and only if** $M(KB) \subset M(\alpha)$ 

E.g.  
ğ¾ğµ = Giants won and Reds won  
$\alpha$ = Giants won

---
**Entailment in Wumpus world**

Situation after detecting nothing in (1,1), moving right, breeze in (2,1).
Consider possible models for the question marks assuming only pits:  
3 boolean choices $\rightarrow$ 8 possible models

![[Screenshot 2023-11-14 at 11.33.11â€¯AM.png|200]]

---
#### Inference

>The definition of entailment can be applied to derive conclusions (logical inference).

Entailment = tells us that $\alpha$ is a consequence of ğ¾ğµ  
Inference = procedure that derives $\alpha$ from ğ¾ğµ

Inference: $ğ¾ğµ |âˆ’_i \alpha =$ sentence a can be derived from ğ¾ğµ by inference algorithm ğ‘–

**Soundness:** 
ğ‘– is sound if whenever $ğ¾ğµ |âˆ’_i \alpha$, it is also true that $ğ¾ğµ |= \alpha$  
**Completeness:**  
ğ‘– is complete if whenever $ğ¾ğµ |= \alpha$, it is also true that $ğ¾ğµ |âˆ’_i \alpha$  

e.g. Model checking is an inference algorithm. It is sound and  
complete when the space of models is finite.

---
#### Knowledge-based agents using propositional (Boolean) logic

##### Propositional logic recap

**Syntax**:
Propositional logic is the simplest logic - illustrates basic ideas 

- The proposition symbols $ğ‘ƒ_1 , ğ‘ƒ_2$ etc. are atomic sentences  
- If $ğ‘†$ is a sentence, Â¬ğ‘† is a sentence (negation)  
- If $ğ‘†_1$ and $ğ‘†_2$ are sentences, $S_1 \wedge S_2$ is a sentence (conjunction)  
- If $ğ‘†_1$ and $ğ‘†_2$ are sentences, $ğ‘†_1 \vee ğ‘†_2$ is a sentence (disjunction)  
- If $ğ‘†_1$ and $ğ‘†_2$ are sentences, $ğ‘†_1 \rightarrow ğ‘†_2$ is a sentence (implication)  
- If $ğ‘†_1$ and $ğ‘†_2$ are sentences, $ğ‘†_1 \leftrightarrow ğ‘†_2$ is a sentence (biconditional)

**Semantics**:
Each model specifies true/false for each proposition symbol

E.g.
$P_1$ false
$P_2$ false
$P_3$ true
is a model
(With these symbols, 8 possible models, can be enumerated automatically.)  

Rules for evaluating truth with respect to a model $m$:
- $\neg P$ is true iff $P$ is false 
- $P_1 \wedge P_2$ is true iff $P_1$ is true and $P_2$ is true
- $P_1 \vee P_2$ is true iff $P_1$ is true or $P_2$ is true
- $P_1 \rightarrow P_2$ is true iff $P_1$ is false or $P_2$ is true
- $P_1 \rightarrow P_2$ is false iff $P_1$ is true and $P_2$ is false
- $P_1 \leftrightarrow P_2$ is true iff $P_1 \rightarrow P_2$ is true and $P_1 \rightarrow P_2$ is true

**Truth tables**

![[Screenshot 2023-11-18 at 5.11.45â€¯PM.png]]

